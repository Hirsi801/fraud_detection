{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo6p3jbfeHr7Ck/xVAUolI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirsi801/fraud_detection/blob/main/fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fraud Detection in Banking Transactions using Unsupervised Learnin"
      ],
      "metadata": {
        "id": "JNjP8xy5yja2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: load the Dataset"
      ],
      "metadata": {
        "id": "oWHvwsobzcNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('fraudTrain.csv')\n",
        "df.head()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYHgMWN4ypF1",
        "outputId": "0c0daa25-3afc-4fd2-cd54-82581901b969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 23 columns):\n",
            " #   Column                 Non-Null Count    Dtype  \n",
            "---  ------                 --------------    -----  \n",
            " 0   Index                  1048575 non-null  int64  \n",
            " 1   trans_date_trans_time  1048575 non-null  object \n",
            " 2   cc_num                 1048575 non-null  float64\n",
            " 3   merchant               1048575 non-null  object \n",
            " 4   category               1048575 non-null  object \n",
            " 5   amt                    1048575 non-null  float64\n",
            " 6   first                  1048575 non-null  object \n",
            " 7   last                   1048575 non-null  object \n",
            " 8   gender                 1048575 non-null  object \n",
            " 9   street                 1048575 non-null  object \n",
            " 10  city                   1048575 non-null  object \n",
            " 11  state                  1048575 non-null  object \n",
            " 12  zip                    1048575 non-null  int64  \n",
            " 13  lat                    1048575 non-null  float64\n",
            " 14  long                   1048575 non-null  float64\n",
            " 15  city_pop               1048575 non-null  int64  \n",
            " 16  job                    1048575 non-null  object \n",
            " 17  dob                    1048575 non-null  object \n",
            " 18  trans_num              1048575 non-null  object \n",
            " 19  unix_time              1048575 non-null  int64  \n",
            " 20  merch_lat              1048575 non-null  float64\n",
            " 21  merch_long             1048575 non-null  float64\n",
            " 22  is_fraud               1048575 non-null  int64  \n",
            "dtypes: float64(6), int64(5), object(12)\n",
            "memory usage: 184.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Unnecessary Columns"
      ],
      "metadata": {
        "id": "CQdBzAQ1zf_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2.1: Remove Unnecessary Columns\n",
        "\n",
        "Several columns are unnecessary for fraud detection, such as:\n",
        "\n",
        "\n",
        "Personal information (first, last, street, city, zip, job, dob) – Doesn't contribute to fraud detection.\n",
        "\n",
        "Transaction ID (trans_num) – Unique ID, not useful for machine learning.\n",
        "\n",
        "Timestamps (trans_date_trans_time, unix_time) – We can extract useful features like hour, day, month instead.\n",
        "\n",
        "Location Data (lat, long, merch_lat, merch_long) – These may be useful, but let's first test without them."
      ],
      "metadata": {
        "id": "YaC8B-H8zuPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df.drop(columns=['Index', 'first', 'last', 'street', 'city', 'zip', 'job', 'dob', 'trans_num'], inplace=True)\n"
      ],
      "metadata": {
        "id": "tsYd3WI4z0v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVConTf51sq8",
        "outputId": "027be0e9-444e-4efa-ac00-9b7d43916e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 14 columns):\n",
            " #   Column                 Non-Null Count    Dtype  \n",
            "---  ------                 --------------    -----  \n",
            " 0   trans_date_trans_time  1048575 non-null  object \n",
            " 1   cc_num                 1048575 non-null  float64\n",
            " 2   merchant               1048575 non-null  object \n",
            " 3   category               1048575 non-null  object \n",
            " 4   amt                    1048575 non-null  float64\n",
            " 5   gender                 1048575 non-null  object \n",
            " 6   state                  1048575 non-null  object \n",
            " 7   lat                    1048575 non-null  float64\n",
            " 8   long                   1048575 non-null  float64\n",
            " 9   city_pop               1048575 non-null  int64  \n",
            " 10  unix_time              1048575 non-null  int64  \n",
            " 11  merch_lat              1048575 non-null  float64\n",
            " 12  merch_long             1048575 non-null  float64\n",
            " 13  is_fraud               1048575 non-null  int64  \n",
            "dtypes: float64(6), int64(3), object(5)\n",
            "memory usage: 112.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values"
      ],
      "metadata": {
        "id": "vOxTitjE2D52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feKSJn7W1ukz",
        "outputId": "87d68201-d3c7-4334-99ea-25efcfca3596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSSNO8N_2FHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Categorical Features"
      ],
      "metadata": {
        "id": "KjDx25ZU2W4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Categorical Variables (One-Hot Encoding)\n",
        "\n",
        "Categorical columns: merchant, category, gender, state\n",
        "\n",
        "Convert them into numerical values using one-hot encoding.\n"
      ],
      "metadata": {
        "id": "Hq6i00NN260G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['merchant', 'category', 'gender', 'state'], drop_first=True)"
      ],
      "metadata": {
        "id": "Y3vw80Rr28jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "1HFfp6ZY4PJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Date-Time Features\n",
        "\n",
        "Since trans_date_trans_time is a timestamp, we extract:\n",
        "\n",
        "Hour – Fraud transactions might be more frequent at odd hours.\n",
        "\n",
        "Day of Week – Some days may have more fraud cases.\n",
        "\n",
        "Month – Seasonal fraud patterns."
      ],
      "metadata": {
        "id": "4TF7SAT44acd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "\n",
        "# Extract time-based features\n",
        "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
        "df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
        "df['month'] = df['trans_date_trans_time'].dt.month\n",
        "\n",
        "# Drop original timestamp column\n",
        "df.drop(columns=['trans_date_trans_time'], inplace=True)\n"
      ],
      "metadata": {
        "id": "I7o0-JW14bFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale Numerical Data"
      ],
      "metadata": {
        "id": "PtJaZ6lI5Eav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling is necessary because the amt column has a large range, which may affect the model."
      ],
      "metadata": {
        "id": "TbOK2tqK5KSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical columns\n",
        "num_cols = ['amt', 'city_pop', 'unix_time']\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n"
      ],
      "metadata": {
        "id": "nliGEF-E5Lzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Features and Target"
      ],
      "metadata": {
        "id": "wCJkbHVv5ZIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features (X): All columns except is_fraud\n",
        "\n",
        "Target (y): is_fraud (1 = Fraud, 0 = Legitimate)"
      ],
      "metadata": {
        "id": "Veyg4Hc15eAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop(columns=['is_fraud'])\n",
        "y = df['is_fraud']\n"
      ],
      "metadata": {
        "id": "G9_NkH6o5fTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is preprocessed, we will train an Isolation Forest model to detect fraudulent transactions"
      ],
      "metadata": {
        "id": "PwAmDjav6WYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Isolation Forest Model"
      ],
      "metadata": {
        "id": "amYktOAc6bW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# # Train Isolation Forest\n",
        "# iso_forest = IsolationForest(n_estimators=200, contamination=0.02, random_state=42, verbose=1)\n",
        "# iso_forest.fit(X)\n",
        "\n",
        "# # Predict anomaly scores\n",
        "# df['Anomaly_Score'] = iso_forest.predict(X)\n",
        "\n",
        "# # Convert -1 (fraud) and 1 (legit) to 1 (fraud) and 0 (legit)\n",
        "# df['Anomaly_Score'] = df['Anomaly_Score'].map({1: 0, -1: 1})\n",
        "\n",
        "# # Count detected fraud cases\n",
        "# print(df['Anomaly_Score'].value_counts())\n"
      ],
      "metadata": {
        "id": "Q5CSTeZb6cQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ],
      "metadata": {
        "id": "xdTtdzYz_5u0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have the actual fraud labels (is_fraud), we can evaluate the model."
      ],
      "metadata": {
        "id": "yGO16QxsAGkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# # True fraud labels\n",
        "# y_true = y  # Original fraud labels\n",
        "# y_pred = df['Anomaly_Score']  # Predictions from Isolation Forest\n",
        "\n",
        "# # Print classification report\n",
        "# print(classification_report(y_true, y_pred))\n",
        "\n",
        "# # Display confusion matrix\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(6,4))\n",
        "# sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "t4JYxJXuAHqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix:\n",
        "\n",
        "True Negatives (TN): 1,032,221 (Correctly classified legitimate transactions)\n",
        "\n",
        "False Positives (FP): 10,348 (Legitimate transactions incorrectly marked as fraud)\n",
        "\n",
        "False Negatives (FN): 5,868 (Fraud cases missed)\n",
        "\n",
        "True Positives (TP): 138 (Correctly identified fraud cases)\n",
        "\n"
      ],
      "metadata": {
        "id": "faCSt04KGdlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Fraud vs. Legit Transactions"
      ],
      "metadata": {
        "id": "g3Q0pe7KDfSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box Plot of Transaction Amount for Fraud vs. Legit\n",
        "# plt.figure(figsize=(10,6))\n",
        "# sns.boxplot(x=df['Anomaly_Score'], y=df['amt'])\n",
        "# plt.xlabel(\"Fraud (1) vs. Legit (0)\")\n",
        "# plt.ylabel(\"Transaction Amount\")\n",
        "# plt.title(\"Transaction Amounts of Fraudulent and Legitimate Transactions\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "Q2cW72iMDhGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot of City Population vs. Transaction Amount\n",
        "# plt.figure(figsize=(10,6))\n",
        "# sns.scatterplot(x=df['city_pop'], y=df['amt'], hue=df['Anomaly_Score'], palette=\"viridis\", alpha=0.6)\n",
        "# plt.xlabel(\"City Population\")\n",
        "# plt.ylabel(\"Transaction Amount\")\n",
        "# plt.title(\"Fraud vs. Legit Transactions\")\n",
        "# plt.legend(title=\"Fraud\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "dL1HYWBpDlaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Save the Model for Deployment"
      ],
      "metadata": {
        "id": "qGNlrKtYFoEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Save trained model\n",
        "# pickle.dump(iso_forest, open(\"fraud_detection_model.pkl\", \"wb\"))\n"
      ],
      "metadata": {
        "id": "yNT6GOIoFpEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Improvement use Other Model"
      ],
      "metadata": {
        "id": "B2Iqxz2wJpkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 1: Apply One-Class SVM for Fraud Detection\n",
        "\n",
        "One-Class SVM is useful for anomaly detection when fraud cases are rare.\n",
        "\n",
        " It learns the normal transaction patterns and flags outliers as fraud."
      ],
      "metadata": {
        "id": "iPBJY4L1KGtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "# Train One-Class SVM\n",
        "one_class_svm = OneClassSVM(nu=0.02, kernel=\"rbf\", gamma=\"auto\")  # Adjust `nu` (0.01 - 0.05)\n",
        "one_class_svm.fit(X)\n",
        "\n",
        "# Predict anomalies\n",
        "df[\"Anomaly_Score\"] = one_class_svm.predict(X)\n",
        "\n",
        "# Convert One-Class SVM output: 1 (Normal) → 0,  -1 (Anomaly/Fraud) → 1\n",
        "df[\"Anomaly_Score\"] = df[\"Anomaly_Score\"].map({1: 0, -1: 1})\n",
        "\n",
        "# Count detected fraud cases\n",
        "print(df[\"Anomaly_Score\"].value_counts())\n"
      ],
      "metadata": {
        "id": "k98XynewKDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "XD9q_wFMKRDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# True fraud labels\n",
        "y_true = y  # Original fraud labels\n",
        "y_pred = df['Anomaly_Score']  # Predictions from Isolation Forest\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzhsS7W7KQbb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}